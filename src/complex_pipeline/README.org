* Complex Pipeline Example
This is an example of how you can construct a more complex pipeline using Azure ML. The pipeline consists of five steps. First, the *data checking* step that checks if the training dataset was updated, if not it cancels the run. The *data cleaning* step then takes the training data, cleans it and writes to temporary files in cloud storage. The cleaned files is then converted to datasets which are fed into the *training step*. The training step trains a model, registers its results and saves the model to its run history and also writes it to a temporary location in blob storage for the next steps to read. Next, the *evaluation step* compares the result of the current run with the results of the model in production, and cancels the pipeline run if there has been no improvement. Finally, the model outputed by the training step is registered in the workspace by the *register step* if the run succeeded.

Note: This example pipeline is overengineered to the point of beeing ridiculous. There probably isn't a point of having the evaulation being separate from the training. And in this case, the data cleaning process is too simple for there to be any point in having it be its own step. Having a separate step for data cleaning is probably more relevant if you have a large quantity of data that needs to be processed, which needs to run on a larger CPU cluster and run in parallell, using a parallell run step.
